---
# An instance of the Experience widget.
# Documentation: https://wowchemy.com/docs/page-builder/
widget: experience

# This file represents a page section.
headless: true

# Order that this section appears on the page.
weight: 40

title: Experience
subtitle:

# Date format for experience
#   Refer to https://wowchemy.com/docs/customization/#date-format
date_format: Jan 2006

# Experiences.
#   Add/remove as many `experience` items below as you like.
#   Required fields are `title`, `company`, and `date_start`.
#   Leave `date_end` empty if it's your current employer.
#   Begin multi-line descriptions with YAML's `|2-` multi-line prefix.
experience:

  - title: Data Engineer Intern
    company: Amazon.com, Inc
    company_url: 'https://www.amazon.com/'
    company_logo: ''
    location: Bellevue, Washington
    date_start: '2023-05-22'
    date_end: '2023-08-11'
    description: |2-

        - Reduced costs by 40% and improved performance by 80% for ETL pipelines and Redshift Clusters, increasing the efficiency of benchmark setting for Amazon Fulfillment Centers through an elaborate dashboard.
        - Optimized identification and rectification of performance detrimental gaps and incorrect keys in sub-par jobs and queries.
        - Proposed innovative AI integration strategies to stimulate growth and promote innovation within existing organizational projects.


  - title: Research Analyst
    company: Luminosity Lab at Arizona State University
    company_url: 'https://theluminositylab.com/'
    company_logo: ''
    location: Tempe, Arizona
    date_start: '2023-01-08'
    date_end: ''
    description: |2-
      [Rodel Project](http://rodel.theluminositylab.com/) -

       - Researched and analyzed predictive tax models to integrate into an innovative and interactive simulator of Arizona to enable leaders and citizens to explore the implications of proposed policies ranging from education to infrastructure hence aiding in informed decision-making.
       - Developed and optimized the user interface using ReactJS and Three.js to improve user experience and responsiveness by 28%.
       - Implemented a KD-Tree Nearest Neighbor model to accurately assign students to schools by considering factors like proximity and school capacity.
      

  - title: Data Science Research Assistant
    company: School of Computing and Augmented Intelligence at Arizona State University
    company_url: 'https://scai.engineering.asu.edu/'
    company_logo: ''
    location: Tempe, Arizona
    date_start: '2022-08-08'
    date_end: '2022-12-24'
    description: |2-

        - Analyzed Arizonaâ€™s Medicaid data, policy changes over the past 5 years, and impact of COVID-19 on Opioid Use Disorder.
        - Identified patterns in treatment gaps to evaluate program effectiveness and remission rates of currently enrolled patients.
        - Managed project progress and stakeholder communication for the State Opioid Response (SOR) initiative.
        - Provided project management support and assistance to ensure project progress and effective communication with key stakeholders for the State Opioid Response (SOR) project.  
       
      

  - title: Machine Learning and Artificial Intelligence Specialist 
    company: EdPlus at Arizona State University
    company_url: 'https://edplus.asu.edu/'
    company_logo: ''
    location: Scottsdale, Arizona
    date_start: '2022-03-01'
    date_end: '2022-08-12'
    description: |2-
        - Developed classification models (CatBoost) to forecast and identify at-risk students leading to 12% increase in success rates over a semester.
        - Aggregated student data to perform quantitative analysis from various data sources and transformed them into actionable insights.
        - Produced data to promote student success by providing target audience lists of students to receive interventions based on the predictions.
        - Reduced fetch and load time by 65% by successfully reproducing SQL queries for Google Data Studio dashboards in BigQuery.
        - Leveraged Google Analytics and BigQuery to track and analyze web behavior and activity aimed at increasing prospective student enrollments for
        the ASUOnline website.
       
  - title: Machine Learning Intern
    company: iPing Data Labs
    company_url: 'https://www.iping.in/'
    company_logo: ''
    location: Mumbai, India
    date_start: '2021-08-01'
    date_end: '2021-11-30'
    description: |2-
        - Developed a deep learning powered Automated Invoice Data Extractor for an Australian client using Python to detect and extract valuable
          information from digital energy invoices using Computer Vision and NLP, eliminating manual labor by 80%.
        - Trained an Object Detection model to localize 10+ relevant data points in 25+ invoice formats to achieve 95%+ F1-Score.
        - Developed and trained various machine learning models for spatial text detection, keyword extraction and company and table identification and
        classification on energy bills and performed statistical inferencing on the results to match stakeholder expectations.
        - Devised a parsing algorithm to extract and structure data from invoice PDFs using Tabula, OCR, and Regex to engineer model data for training.
        - Interpreted 1,25,000+ images from CCTV feeds to detect 7 object categories during day and night for Traffic Detection and Tracking.
    
  - title: Team Lead and Software Development Intern
    company: TinkTank
    company_url: 'http://tinktank.co.in/'
    company_logo: ''
    location: Mumbai, India
    date_start: '2020-05-01'
    date_end: '2020-12-31'
    description: |2-
        - Led a team of 4 interns and contributed heavily to brainstorming and executing an end-to-end workflow to build an analytics tool that enables
          recruiters and hiring managers to analyze, track and visualize team performance metrics/KPIs.
        - Implemented a Business Rule Engine in Python that performed Custom Data Validation on 40+ attributes to obtain clean data for visualization
          using custom dashboards for each user type.
        - Designed and developed the ETL pipeline to map data from complex datasets and multiple data sources using PostgreSQL and Django.

design:
  columns: '2'
---
